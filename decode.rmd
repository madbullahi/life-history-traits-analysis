---
title: "Decode Analysis"
output: rmarkdown::github_document
author: "Muhammad Abdullahi"
date: "29/2/2024"
---

***************Load the required libraries***************
*******************************************************


```{r}

library(tidymodels)
library(readxl)
library(rcompanion)
library(lmerTest)
```


***************Load the data***************

```{r}

Data <- read_excel("C:/Users/mxa1132-admin/OneDrive/Documents/life-history-traits-analysis/Decode_Analysis.xlsx") # load the data

```

```{r}
print(Data) # print the data
```

```{r}
summary(Data) # summary of the data
view(Data) # view the data

```

***************Data Preprocessing***************

```{r}
# convert the variables to factors

Data$pop <-  factor(Data$pop, levels = c("P", "E"))
Data$cond <-  factor(Data$cond, levels = c("LA", "HA"))

```


```{r}

colSums(is.na(Data)) # check for missing values

```

```{r}
str(Data) # structure of the data
```
```{r}
Decode_Data <-Data

```


```{r}
Decode_Data$pop <-  factor(Decode_Data$pop, levels = c("P", "E"))
Decode_Data$cond <-  factor(Decode_Data$cond, levels = c("LA", "HA"))
                           
```


```{r}
# select cloumns 5 to 8 

Dacode_Data <- Decode_Data[,c(5:8)]
Dacode_Data
```


```{r}
# remove the missing values

Data_without_NAs <-  Decode_Data[complete.cases(Decode_Data),]
Data_without_NAs

```
```{r}
DD <- Data_without_NAs
```


```{r}
# log transformation of the variables

DD[5:8] <- log(DD[5:8] +0.5)
DD
```
```{r}
log_DD <-  DD[, c(5:8)]

```

```{r}
# run the PCA

PCA1 <- prcomp(log_DD, scale = TRUE)
```

```{r}
# print the PCA results
print(PCA1)
```

```{r}
summary(PCA1)
```

```{r}
#  load the libraries to plot the pca
pop <- as.factor(DD$pop)
cond <-  as.factor(DD$cond)
```


```{r}
p <- fviz_pca_ind(PCA1, habillage = cond, geom = "point",
                  ellipse.level = 0.68,
                  addEllipses = T) +
  xlim(-4, 4) + ylim(-4, 4) # plot the pca
p
```


```{r}

# save the plot
 ggsave("pca2_plot.png", p, width = 10, height = 10, units = "cm")
```




```{r}
#  check for outliers in the pca

U <-  PCA1$x  # coordinates of individuals
```

```{r}
threshold <- 3 # set the threshold

apply(U, 2, function(x) which(abs(x - mean(x)) > threshold * sd(x)))
```


```{r}

qplot(U[, 1], U[, 2], colour = factor(cond) ) + coord_equal()
```

```{r}
ind.oout <- apply(U, 2, function(x) which(abs(x - mean(x)) > threshold * sd(x))) %>% 
  Reduce(union, .) %>%
  print()# find outliers

```

```{r}
col <- rep("black", nrow(U)); col[ind.oout] <- "red"
qplot(U[, 1], U[, 2], colour = I(col), size = I(2)) + coord_equal()
```

******************Robust PCA******************
1. computes the absolute difference of each column in the matrix U from its median, 
divided by the MAD of that column.
2. calculates a robust covariance distance using the covRob.
****************************************************

```{r}
# robust Mahalanobis distance
dist <- apply(U, 2, function(x) abs(x - median(x)) / mad(x)) %>%  
                apply(1, max) 

dist1 <-  covRob(U, estim = "pairwiseGK")$dist
qqplot(dist, sqrt(dist1))

```


```{r}
# extract the pca scores

pca_scores <-  as.data.frame(PCA1$x)
```


```{r}

# Run K-mean clustering on the scores

Kmeans_cluster <-  kmeans(pca_scores, centers = 2)
```

```{r}
#  visualise the clustering results

plot(pca_scores, col = Kmeans_cluster$cluster, pch = 20, cex = 2)

```



```{r}
# find and print outlier values in each column of the PCA
U_no_outliers <- U
  
outliers <- apply(U, 2, function(x) which( abs(x - mean(x)) > (threshold * sd(x)) )) # find outliers

```





```{r}
for (i in 1:ncol(U)) {  
    U_no_outliers[outliers[[i]], i] <- NA 
  }
```


```{r}
# print the outliers  
U_no_outliers

```


```{r}
# If U_no_outliers has fewer rows, subset Data to match
Data_subset <- Data[1:nrow(U_no_outliers), ]

# Combine the datasets with matching rows
linked_data <- cbind(Data_subset, U_no_outliers)

```

```{r}


view(linked_data) # view the combined data

```


```{r}

original_colnames <- c("sumNeo", "adult", "diff", "size")
```


```{r}
# Rename the columns in the linked dataframe to match the original dataset
colnames(linked_data)[9:12] <- original_colnames

view(linked_data) # view the combined data

```

```{r}

# save the combined data

write.csv(linked_data, "linked_data.csv")

```

```{r}

 U_no_outliers


```

```{r}

remove_NAs <- U_no_outliers[complete.cases(U_no_outliers), ]

```


```{r}

apply(U_no_outliers, 2, function(x) which(abs(x - mean(x)) > threshold * sd(x)))

```

```{r}

qplot(U_no_outliers[, 1], U_no_outliers[, 2], colour = factor(cond) ) + coord_equal()

```





```{r}
# function to remove outliers from a specific column.
remove_outliers <- function(column) {
  mean_col <-  mean(column)
  sd_col <-  sd(column)
  outliers_col <- column[abs(column - mean_col) > threshold * sd_col]
  cleaned_column <-  column[!(column %in% outliers_col)]
  return(cleaned_column)
}


```

```{r}
# apply the fuction to each column where you want to removew outliers

cleaned_df <- Data

```


```{r}
# Pad cleaned data to match original dataframe's length
#cleaned_data <- c(remove_outliers(cleaned_df$adult), rep(NA, nrow(cleaned_df) - length(remove_outliers(cleaned_df$adult))))
#cleaned_data <- c(remove_outliers(cleaned_df$diff), rep(NA, nrow(cleaned_df) - length(remove_outliers(cleaned_df$diff))))
#cleaned_data <- c(remove_outliers(cleaned_df$size), rep(NA, nrow(cleaned_df) - length(remove_outliers(cleaned_df$size))))
#cleaned_data <- c(remove_outliers(cleaned_df$sumNeo), rep(NA, nrow(cleaned_df) - length(remove_outliers(cleaned_df$sumNeo))))



# Assign padded data back to the 'adult' column
#cleaned_df$adult <- cleaned_data
#cleaned_df$diff <- cleaned_data
#cleaned_df$size <- cleaned_data
#cleaned_df$sumNeo <- cleaned_data
#cleaned_df


```


```{r}

# import the cleaned excel file
 
clean_raw_data <- read.csv("cleaned_data.csv")
clean_raw_data
view(clean_raw_data)
```

```{r}

# remove NAs from the cleaned data

colSums(is.na(clean_raw_data))
```

```{r}

raw_clean_data <- clean_raw_data[complete.cases(clean_raw_data), ]
raw_clean_data

```

```{r}
log_raw_clean_data <- raw_clean_data
```

```{r}

# log transformation of the variables
log_raw_clean_data[5:8] <-  log(log_raw_clean_data[5:8] + 0.5)
log_raw_clean_data

```

```{r}
# convert the variables to factors

log_raw_clean_data$cond <- factor(log_raw_clean_data$cond, levels = c("AL", "HA"))
log_raw_clean_data$pop <- factor(log_raw_clean_data$pop, levels = c("P", "E"))
```

```{r}
# subset the variables for subsequent analysis

log_subset_data <- log_raw_clean_data[,c(5:8)]
log_subset_data

```

```{r}
# run PCA on the log transformed subsetted data

PCA2 <- prcomp(log_subset_data, scale = TRUE)
print(PCA2)
summary(PCA2)

```

```{r}
# plot the PCA results

pca_plot <- fviz_pca_ind(PCA2, geom.ind = "point", col.ind = log_raw_clean_data$cond, 
                        addEllipses = TRUE, ellipse.level = 0.95, 
                         legend.title = "Condition", repel = TRUE)
pca_plot
```

```{r}
# make a plot of PCA inlcuding the response variables.
respone_biplot <-  fviz_pca_biplot(PCA2,
                                   habillage = raw_clean_data$pop,
                                   palette = c("P" = "red", "E" = "black"),
                                   addEllipses = TRUE,
                                   col.var = "blue",
                                   arrowsize = 0.2,
                                   labelsize = 5,
                                   geom.ind = "point",
                                   pointshape = 19,
                                   pointsize = 3,
                                   mean.point = F,
                                   repel = TRUE,
                                   legend.title = "Population",
                                   ellipse.type = "confidence",
                                   var.scale = 0.5,
                                   xlim = c(-3, 3),
                                   ylim = c(-5, 5),
                                  shape.ind = log_raw_clean_data$cond)

                                   

respone_biplot
```
```{r}
# save the PCA plot

ggsave("PCA_biplot.png", respone_biplot, width = 10, height = 10, units = "in", dpi = 300)

```

```{r}
# calculate the summary statistics for the variable age.
age_summary <- summarySE(raw_clean_data, measurevar = "adult", groupvars = c("cond", "pop"))
age_summary
```

```{r}
# makke a plot of the summary statistics for the variable age.
Age <- ggplot(age_summary,
                        aes(x = cond,
                            y = adult,
                            colour = pop,
                            group = interaction(pop))) +
    geom_errorbar(aes(ymin = adult - se,
                      ymax = adult + se),
                  width = 0.1,
                  position = pd) +
    geom_line(position = pd) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.line = element_line(colour = "black"),
          aspect.ratio = 1,
          panel.border = element_rect(colour = "black", fill = NA, size = 0.5)) +
    labs(x = "Treatment",
         y = "Age at Maturity",
         colour = "pop")
Age
```



```{r}
# make the summary statistics for the variable size

size <- summarySE(raw_clean_data, measurevar = "size", groupvars = c("cond", "pop"))
size


```

```{r}

# make a plot of the summary statistics for the variable size

Size <- ggplot(size,
                        aes(x = cond,
                            y = size,
                            colour = pop,
                            group = interaction(pop))) +
    geom_errorbar(aes(ymin = size - se,
                      ymax = size + se),
                  width = 0.1,
                  position = pd) +
    geom_line(position = pd) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.line = element_line(colour = "black"),
          aspect.ratio = 1,
          panel.border = element_rect(colour = "black", fill = NA, size = 0.5)) +
    labs(x = "Treatment",
         y = "Size",
         colour = "pop")
Size
```

```{r}
# make a summary statistics for the variable sumNeo

fecundity <- summarySE(raw_clean_data, measurevar = "sumNeo", groupvars = c("cond", "pop"))
fecundity
```

```{r}
# make a plot of the summary statistics for the variable sumNeo
fecundity_plot <- ggplot(fecundity,
                        aes(x = cond,
                            y = sumNeo,
                            colour = pop,
                            group = interaction(pop))) +
    geom_errorbar(aes(ymin = sumNeo - se,
                      ymax = sumNeo + se),
                  width = 0.1,
                  position = pd) +
    geom_line(position = pd) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.line = element_line(colour = "black"),
          aspect.ratio = 1,
          panel.border = element_rect(colour = "black", fill = NA, size = 0.5)) +
    labs(x = "Treatment",
         y = "Fecundity",
         colour = "pop")
fecundity_plot
```

```{r}
# make a summary statistics for the variable diff
diff_summary <- summarySE(raw_clean_data, measurevar = "diff", groupvars = c("cond", "pop"))
diff_summary
```

```{r}
# make a plot of the summary statistics for the variable diff
diff_plot <- ggplot(diff_summary,
                        aes(x = cond,
                            y = diff,
                            colour = pop,
                            group = interaction(pop))) +
    geom_errorbar(aes(ymin = diff - se,
                      ymax = diff + se),
                  width = 0.1,
                  position = pd) +
    geom_line(position = pd) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.line = element_line(colour = "black"),
          aspect.ratio = 1,
          panel.border = element_rect(colour = "black", fill = NA, size = 0.5)) +
    labs(x = "Treatment",
         y = "Difference",
         colour = "pop")
diff_plot
```
********************hypothesis testing****************
```{r}
# peform the anova test for the variable adult
set.seed(123)
age_anova <- lmer(log(adult) ~ cond * pop + (1|pop:Genotypes:Replicates), data = raw_clean_data)

anova(age_anova)
```


```{r}
# check for normality of the residuals (age)
qqnorm(resid(age_anova),
       ylab = "Residuals")

qqline(residuals(age_anova),
       col = "red")

```

```{r}
library(rcompanion)

age_resid <-  residuals(age_anova)

plotNormalHistogram(age_resid)
```
```{r}
shapiro.test(age_resid) # test for normality
```



```{r}
# perform the anova test for the variable size
size_anova <- lmer(log(size) ~ cond * pop + (1|pop:Genotypes:Replicates), data = raw_clean_data)
anova(size_anova)
```


```{r}
qqnorm(residuals(size_anova),
       ylab = "Residuals")
qqline(resid(size_anova),
       col = "red")

size_resid <-  residuals(size_anova)
plotNormalHistogram(size_resid)

```
```{r}

shapiro.test(size_resid) # test for normality
```


```{r}
# perform the anova test for the variable sumNeo
fecundity_anova <- lmer(log(sumNeo) ~ cond * pop + (1|pop:Genotypes:Replicates), data = raw_clean_data)
anova(fecundity_anova)
```


```{r}
qqnorm(residuals(fecundity_anova),
       ylab = "Residuals")
qqline(resid(fecundity_anova),
       col = "red")

fecundity_resid <-  residuals(fecundity_anova)
plotNormalHistogram(fecundity_resid)

```

```{r}

shapiro.test(fecundity_resid) # test for normality
```

```{r}
# perform the anova test for the variable diff
diff_anova <- lmer(log(diff) ~ cond * pop + (1|pop:Genotypes:Replicates), data = raw_clean_data)
anova(diff_anova)
```

```{r}
qqnorm(residuals(diff_anova),
       ylab = "Residuals")
qqline(resid(diff_anova),
       col = "red")

diff_resid <-  residuals(diff_anova)
plotNormalHistogram(diff_resid)

```

```{r}

shapiro.test(diff_resid) # test for normality
```

```{r}
```

```{r}
# manova for the four variables
Y <-  cbind(raw_clean_data$adult, raw_clean_data$size, raw_clean_data$sumNeo, raw_clean_data$diff)
```

```{r}
model_mano <-  manova(log(Y) ~ cond * pop , data = raw_clean_data)
summary(model_mano, test = "Pillai")
```
**********PTA Analysis************
```{r}
Data_PTA <- raw_clean_data
Data_PTA$pop <- factor(Data_PTA$pop, levels = c("E", "P"))
Data_PTA$cond <- factor(Data_PTA$cond, levels = c("AL", "HA"))

```

```{r}

Data_PTA_without_NAs <-  Data_PTA[complete.cases(Data_PTA),]
Data_PTA_without_NAs
```


```{r}
Data_PTA_without_NAs[5:8] <- log(Data_PTA_without_NAs[5:8] + 0.5)
```

```{r}
# create your table variables

AL <-  Data_PTA_without_NAs[Data_PTA_without_NAs$cond == "AL",]
HA <-  Data_PTA_without_NAs[Data_PTA_without_NAs$cond == "HA",]
```

```{r}
taxa <- as.factor(Data_PTA_without_NAs$pop)
```

```{r}
level <-  as.factor(Data_PTA_without_NAs$cond)
```

```{r}
Y <-  as.matrix(Data_PTA_without_NAs[-c(1:4)])
```

```{r}
taxaBylevel <-  as.factor(paste(taxa, level))
```


```{r}
Y <-  prcomp(Y)$x
```

```{r}
n <-  length(levels(taxa))
```

```{r}
p <- length(levels(level))
```

```{r}
k <- ncol(Y)
k
```

```{r}
# manova

lm.full <-  lm(Y ~ taxa * level, model = T, x = T, y = T, qr = T)

yhat.full <- predict(lm.full)
```

```{r}
summary(manova(lm.full))
```

```{r}
# for resid randomization (used later)
lm.red <- lm(Y ~ taxa +level, model = T, x = T, y = T, qr = T) # create the model just for the covariate

yhat.red <- predict(lm.red) # predict the model

res.red <- resid(lm.red) # create the residuals

res.red
```


```{r}
lsmeans.obs <- NULL
for (i in 1:k) {
  mean.temp <- tapply(yhat.full[,i], taxaBylevel, mean)
  lsmeans.obs <- cbind(lsmeans.obs, mean.temp)  
}

lsmeans.obs

```

```{r}
arrayspecs <- function(A){
  n.m <-NULL # n.m stands for new means
  for(i in 1:n){
    temp <-as.matrix(A[((1+(i-1)*p):(i*p)),1:k])
    n.m <-cbind(n.m, temp)}
  trajectories <- array(n.m, dim = c(p, k, n))
}


```


*****************Function calculating trajectory attributes************
```{r}
# Pathlength distance
pathdist<-function(M) {as.matrix(dist(M))}
trajsize<-function(M){
  traj.pathdist<-array(0,dim=c(n,1))   		#loop across trajectories
  for (i in 1:n){
    temp<-pathdist(M[,,i])
    for (j in 1:(p-1)){
      traj.pathdist[i]<-traj.pathdist[i]+temp[j,j+1]
    }
  }
  traj.size.dist<-as.matrix(dist(traj.pathdist))		#TrajSizeDiff
}

#trajectory direction 
orient<-function(M) {(svd(var(M))$v[1:k,1])} 	#find orientation

trajorient<-function(M){
  traj.orient<-array(NA,dim=c(n,k))   		#loop across trajectories
  check.1<-array(NA,dim=c(n))
  for (i in 1:n){
    temp<-orient(M[,,i])
    traj.orient[i,]<-temp
    check.1[i]<-M[1,,i]%*%traj.orient[i,]  #check startingpoint location
    check.1[i]<-check.1[i]/abs(check.1[i])
    if(check.1[i]==-1) traj.orient[i,]<--1*traj.orient[i,]
  }
  options(warn=-1)				#b/c acos of 1 (e.g, on diagonal) yields warning
  traj.ang.diff<-(180/pi)*acos(traj.orient%*%t(traj.orient))
  #diag(traj.ang.diff)<-0
}




```


```{r}

#trajectory shape
### GPA: following J.claude 2008; Morphometrics in R

trans <-function(A){scale(A, scale=F)} ##TRANSLATION


csize<-function(A)  ##CSIZE
{p<-dim(A)[1]
size<-sqrt(sum(apply(A,2,var))*(p-1))
list("centrois_size"=size, "scaled"= A/size)
}
  
  
mshape<-function(A){apply(A,c(1,2), mean)}  #meanshape

pPsup<- function(M1,M2){                    ## OPA rotation 1-->2
  k<-ncol(M1)
  Z1<-trans(csize(M1)[[2]])
  Z2<-trans(csize(M2)[[2]])
  sv<-svd(t(Z2)%*%Z1)
  U<-sv$u; V<-sv$u;Delt<-sv$d
  sig<-sign(det(t(Z1)%*%Z2))
  Delt[k]<-sig*abs(Delt[k]); V[,k]<-sig*V[,k]
  Gam<-U%*%t(V)
  beta<-sum(Delt)
  list(Mp1=beta*Z1%*%Gam,Mp2=Z2,rotation=Gam,scale=beta,
       df=sqrt(1-beta^2))
}
pgpa<-function(A)
{p<-dim(A)[1]; k<-dim(A)[2]; n<-dim(A)[3]  
temp2<-temp1<-array(NA,dim=c(p,k,n)); Siz<-numeric(n)#; Qm2<-numeric(n)
for (i in 1:n)
{Acs<-csize(A[,,i])
Siz[i]<-Acs[[1]]
temp1[,,i]<-trans(Acs[[2]])}
Qm1<-dist(t(matrix(temp1,k*p,n)))
Q<-sum(Qm1); iter<-0
while (abs(Q)> 0.00001)
{for(i in 1:n){
  M<-mshape(temp1[,,-i])
  temp2[,,i]<-pPsup(temp1[,,i],M)[[1]]}
  Qm2<-dist(t(matrix(temp2,k*p,n)))
  Q<-sum(Qm1)-sum(Qm2)
  Qm1<-Qm2
  iter=iter+1
  temp1<-temp2}
list("rotated"=temp2,"it.number"=iter,"Q"=Q,"intereucl.dist"=Qm2,"mshape"=
       csize(mshape(temp2))[[2]],"cent.size"=Siz)
}


```


```{r}
## loop for GPA and shape distances
trajshape <- function(M){
  x<-pgpa(M)
  traj.shape.dist<-as.matrix(dist(x$intereucl.dist))
}


```

```{r}
## TrajectrorySummaryStat

sumstat<-function(M){
  M<-as.dist(M)
  x<-if(length(M)>1)(x=var(M)) else 0
  
}

```

```{r}
#########Main Loop########

traj.specs.obs<-arrayspecs(lsmeans.obs) #lsmeans.obs is the output of the main loop
trajsize.obs<-trajsize(traj.specs.obs)
trajdir.obs<-trajorient(traj.specs.obs)
diag(trajdir.obs)<-0 #b/c some NA/N values on diagonal)
trajshape.obs<-trajshape(traj.specs.obs)
sumstatsize.obs<-sumstat(trajsize.obs)
sumstatdir.obs<-sumstat(trajdir.obs)
sumstatshape.obs<-sumstat(trajshape.obs)

```

```{r}

#### PERMUTATION Procedure

permute<-1000
line<-nrow(Y)
PSize<-POrient<-PShape<-array(1,dim=c(n,n))
PSumSize<-PSumOrient<-PSumShape<-1
for(i in 1:permute){
  line.rand<-sample(line,replace=FALSE)
  res.temp<-cbind(line.rand,res.red)
  z<-(order(line.rand))
  res.temp2<-as.matrix(res.temp[z,])
  res.p<-res.temp2[,-1] # Rows of residual are now randomized
  y.rand<-yhat.red+res.p
  yhat.rand<-predict(lm(y.rand~taxa*level,model=T,x=T,y=T,qr=T))
  
  lsmeans.rand<-NULL
  for (j in 1:k){
    mean.temp<-tapply(yhat.rand[,j],taxaBylevel, mean)
    lsmeans.rand<-cbind(lsmeans.rand,mean.temp)
  }
  traj.specs.rand<-arrayspecs(lsmeans.rand)
  trajsize.rand<-trajsize(traj.specs.rand)
  trajdir.rand<-trajorient(traj.specs.rand)
  diag(trajdir.rand)<-0 #b/c some NA/N values on diagonal)
  trajshape.rand<-trajshape(traj.specs.rand)
  sumstatsize.rand<-sumstat(trajsize.rand)
  sumstatdir.rand<-sumstat(trajdir.rand)
  sumstatshape.rand<-sumstat(trajshape.rand)
  for(j in 1:n){
    for(jj in 1:n){
      PSize[j,jj]<-if(trajsize.rand[j,jj]>=trajsize.obs[j,jj])
        (PSize[j,jj]+1) else PSize[j,jj]
      POrient[j,jj]<-if(trajdir.rand[j,jj]>=trajdir.obs[j,jj])
        (POrient[j,jj]+1) else POrient[j,jj]
      PShape[j,jj]<-if(trajshape.rand[j,jj]>=trajshape.obs[j,jj])
        (PShape[j,jj]+1) else PShape[j,jj]
    }
  }
  PSumSize<-if(sumstatsize.rand>=sumstatsize.obs) (PSumSize+1) else PSumSize
  PSumOrient<-if(sumstatdir.rand>=sumstatdir.obs) (PSumOrient+1) else PSumOrient
  PSumShape<-if(sumstatshape.rand>=sumstatshape.obs) (PSumShape+1) else PSumShape
} #end of permutation loop
for (j in 1:n){
  for(jj in 1:n){
    PSize[j,jj]<-PSize[j,jj]/(permute+1)
    POrient[j,jj]<-POrient[j,jj]/(permute+1)
    PShape[j,jj]<-PShape[j,jj]/(permute+1)
  }
}
PSumSize<-PSumSize/(permute+1)
PSumOrient<-PSumOrient/(permute+1)
PSumShape<-PSumShape/(permute+1)



```


```{r}

trajsize.obs # trajectore magnitude, length of line
PSize
trajdir.obs # trajectory direction, distance between two dots
POrient 
#trajshape.obs # trajectory shape, distance between two lines
#PShape

```
```{r}
###NOTE: summary statistics only valid for 2+ trajectories!!
sumstatsize.obs
PSumSize
sumstatdir.obs
PSumOrient
#sumstatshape.obs
#PSumShape

```
```{r}
#############Plot Data and LS means
plot(Y[,1:2], type="n", xlab="PC1", ylab="PC2", asp=1)
YY=cbind(taxa,level,Y)
points(YY[,3:4],col=taxa, pch=c(1,19)[as.numeric(level)])
for(i in 1:n){
  for(j in 1:(p-1)){
    points(traj.specs.obs[(j:(j+1)),1,i],traj.specs.obs[(j:(j+1)),2,i],type="l",pch=21,col="black")
    
  }
}
for (i in 1:n){
  for(j in 2:(p-1)){
    points(traj.specs.obs[j,1,i],traj.specs.obs[j,2,i],pch=21,col="red", cex=1.5)
  }
}
for(i in 1:n){
  points(traj.specs.obs[1,1,i],traj.specs.obs[1,2,i],pch=21,col="blue", cex=1.5, bg="white")
}
for(i in 1:n){
  points(traj.specs.obs[p,1,i],traj.specs.obs[p,2,i],pch=21,col="black", cex=1.5, bg="black")
}

```
